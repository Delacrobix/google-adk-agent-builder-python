{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e2d8c5",
   "metadata": {},
   "source": [
    "# Build a Voice-Powered Kitchen Assistant with Google ADK and Elastic Agent Builder - Setup\n",
    "\n",
    "Learn to build a voice assistant that queries Elasticsearch using Google ADK and Agent Builder. Covers MCP protocol, LiveAPI voice streaming and semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slg0ll184wq",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install the required Python packages for Elasticsearch connectivity and environment variable management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b274cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c6f52",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Create a `.env` file in this directory with your credentials:\n",
    "\n",
    "```\n",
    "ES_ENDPOINT=\n",
    "KIBANA_ENDPOINT=\n",
    "ES_API_KEY=\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j5qtw2q384d",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import all necessary libraries for working with Elasticsearch, handling JSON data, and making HTTP requests to the Kibana API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6880907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ccdc8",
   "metadata": {},
   "source": [
    "## Declare Variables and Initialize Elasticsearch Client\n",
    "\n",
    "Set up environment variables and create the Elasticsearch client. Also define the index name and inference endpoint ID that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8f87053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_ENDPOINT = os.getenv(\"ES_ENDPOINT\")\n",
    "KIBANA_ENDPOINT = os.getenv(\"KIBANA_ENDPOINT\")\n",
    "ES_API_KEY = os.getenv(\"ES_API_KEY\")\n",
    "\n",
    "es_client = Elasticsearch(ES_ENDPOINT, api_key=ES_API_KEY)\n",
    "\n",
    "INDEX_NAME = \"cooking-recipes\"\n",
    "INFERENCE_ID = \"jina-embeddings\"\n",
    "\n",
    "KIBANA_HEADERS = {\n",
    "    \"Authorization\": f\"ApiKey {ES_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"kbn-xsrf\": \"true\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "namw3odb3qp",
   "metadata": {},
   "source": [
    "## Create Inference Endpoint\n",
    "\n",
    "Create a text embedding inference endpoint using Jina Embeddings v3, a high-quality retrieval model provided by Elastic. This endpoint will be used for semantic search capabilities in our recipe index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06cebe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference endpoint 'jina-embeddings' created successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Create inference endpoint with Jina embeddings v3\n",
    "    inference_config = {\n",
    "        \"service\": \"elastic\",\n",
    "        \"service_settings\": {\"model_id\": \"jina-embeddings-v3\"},\n",
    "    }\n",
    "\n",
    "    es_client.inference.put(\n",
    "        task_type=\"text_embedding\", inference_id=INFERENCE_ID, body=inference_config\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Inference endpoint '{INFERENCE_ID}' created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating inference endpoint: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014vpgryicxb",
   "metadata": {},
   "source": [
    "## Create Knowledge Index\n",
    "\n",
    "Create the `knowledge` index with a mapping that includes:\n",
    "- **Text fields**: `name`, `ingredients`, `procedure` - for full-text search\n",
    "- **Keyword fields**: `allergens`, `category`, `dietary` - for filtering and aggregations\n",
    "- **Semantic field**: Uses `semantic_text` type with Jina embeddings for semantic search\n",
    "\n",
    "The `copy_to` property aggregates content from multiple fields into `semantic_field` for unified semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceafb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    es_client.indices.exists(index=INDEX_NAME)\n",
    "\n",
    "    knowledge_mapping = {\n",
    "        \"properties\": {\n",
    "            \"name\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"ingredients\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"allergens\": {\"type\": \"keyword\", \"copy_to\": \"semantic_field\"},\n",
    "            \"procedure\": {\"type\": \"text\", \"copy_to\": \"semantic_field\"},\n",
    "            \"prep_time_minutes\": {\"type\": \"integer\"},\n",
    "            \"category\": {\"type\": \"keyword\", \"copy_to\": \"semantic_field\"},\n",
    "            \"dietary\": {\"type\": \"keyword\", \"copy_to\": \"semantic_field\"},\n",
    "            \"semantic_field\": {\n",
    "                \"type\": \"semantic_text\",\n",
    "                \"inference_id\": INFERENCE_ID,\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_client.indices.create(index=INDEX_NAME, mappings=knowledge_mapping)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kv8s7yxgb9",
   "metadata": {},
   "source": [
    "## Ingest Recipe Data\n",
    "\n",
    "Load recipe data from `dataset.json` and bulk index it into Elasticsearch. The bulk API is used for efficient ingestion of multiple documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "779645dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 documents indexed successfully\n"
     ]
    }
   ],
   "source": [
    "def build_bulk_actions(documents, index_name):\n",
    "    for doc in documents:\n",
    "        yield {\"_index\": index_name, \"_source\": doc}\n",
    "\n",
    "\n",
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    knowledge_docs = json.load(f)\n",
    "\n",
    "success, failed = helpers.bulk(\n",
    "    es_client,\n",
    "    build_bulk_actions(knowledge_docs, INDEX_NAME),\n",
    "    refresh=True,\n",
    ")\n",
    "print(f\"{success} documents indexed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tjwrtqt1799",
   "metadata": {},
   "source": [
    "## Create Agent Builder Tool\n",
    "\n",
    "Register a semantic search tool in Agent Builder via the Kibana API. This tool:\n",
    "- **ID**: `recipe_semantic_search` - unique identifier used by the ADK agent\n",
    "- **Type**: `index_search` - performs searches on Elasticsearch indices\n",
    "- **Tags**: `semantic` - enables semantic search capabilities\n",
    "\n",
    "The tool description guides the agent on when and how to use this tool for recipe queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e901e48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Recipe semantic search tool created successfully\n"
     ]
    }
   ],
   "source": [
    "recipe_search_tool = {\n",
    "    \"id\": \"recipe_semantic_search\",\n",
    "    \"type\": \"index_search\",\n",
    "    \"description\": \"Search kitchen recipes including ingredients, allergens, dietary restrictions, preparation procedures, and cooking times. Uses semantic search to find relevant recipes even without exact keyword matches.\",\n",
    "    \"tags\": [\"semantic\"],\n",
    "    \"configuration\": {\n",
    "        \"pattern\": INDEX_NAME,\n",
    "    },\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{KIBANA_ENDPOINT}/api/agent_builder/tools\",\n",
    "        headers=KIBANA_HEADERS,\n",
    "        json=recipe_search_tool,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"✅ Recipe semantic search tool created successfully\")\n",
    "    elif response.status_code == 400:\n",
    "        # Check if it's because the tool already exists\n",
    "        if \"already exists\" in response.text.lower():\n",
    "            print(\"ℹ️  Recipe search tool already exists, continuing...\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"⚠️  Failed to create tool: {response.status_code}. \\n Response: {response.text}\"\n",
    "            )\n",
    "    else:\n",
    "        print(\n",
    "            f\"⚠️  Failed to create tool: {response.status_code}. \\n Response: {response.text}\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating tool: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ijf9i750ly",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n",
    "\n",
    "Run the following cells to clean up all resources created in this notebook. This includes:\n",
    "1. Deleting the Agent Builder tool\n",
    "2. Deleting the Elasticsearch index\n",
    "3. Deleting the inference endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ke4zkp11yph",
   "metadata": {},
   "source": [
    "### Delete Agent Builder Tool\n",
    "\n",
    "Remove the semantic search tool from Agent Builder using the Kibana API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "v8q4y4utnss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Tool 'recipe_semantic_search' not found, may have already been deleted\n"
     ]
    }
   ],
   "source": [
    "TOOL_ID = \"recipe_semantic_search\"\n",
    "\n",
    "try:\n",
    "    response = requests.delete(\n",
    "        f\"{KIBANA_ENDPOINT}/api/agent_builder/tools/{TOOL_ID}\",\n",
    "        headers=KIBANA_HEADERS,\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✅ Agent Builder tool '{TOOL_ID}' deleted successfully\")\n",
    "    else:\n",
    "        print(f\"ℹ️  Tool '{TOOL_ID}' not found, may have already been deleted\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error deleting tool: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8sct9astlb",
   "metadata": {},
   "source": [
    "### Delete Elasticsearch Index\n",
    "\n",
    "Remove the knowledge index containing the recipe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7761d327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Index 'cooking-recipes' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    es_client.indices.delete(index=INDEX_NAME)\n",
    "    print(f\"✅ Index '{INDEX_NAME}' deleted successfully\")\n",
    "except Exception as e:\n",
    "    if \"index_not_found_exception\" in str(e):\n",
    "        print(f\"ℹ️  Index '{INDEX_NAME}' not found, may have already been deleted\")\n",
    "    else:\n",
    "        print(f\"❌ Error deleting index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3wuqqhzd6p3",
   "metadata": {},
   "source": [
    "### Delete Inference Endpoint\n",
    "\n",
    "Remove the Jina embeddings inference endpoint from Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "yx3c5ottd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference endpoint 'jina-embeddings' deleted successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    es_client.inference.delete(inference_id=INFERENCE_ID)\n",
    "    print(f\"✅ Inference endpoint '{INFERENCE_ID}' deleted successfully\")\n",
    "except Exception as e:\n",
    "    if \"resource_not_found_exception\" in str(e):\n",
    "        print(\n",
    "            f\"ℹ️  Inference endpoint '{INFERENCE_ID}' not found, may have already been deleted\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"❌ Error deleting inference endpoint: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
